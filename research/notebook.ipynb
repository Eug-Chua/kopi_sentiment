{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts(limit=5)\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=3)\n",
    "posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[1].comments[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=2)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Comments ({len(post.comments)}):\")\n",
    "    for comment in post.comments[:3]:  # Show first 3 comments\n",
    "        print(f\"  - {comment[:100]}...\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=2)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Comments ({len(post.comments)}):\")\n",
    "    for comment in post.comments[:5]:\n",
    "        print(f\"  [+{comment.score}] {comment.text[:80]}...\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "from kopi_sentiment.analyzer.claude import ClaudeAnalyzer\n",
    "\n",
    "# Fetch a post with comments\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=1)\n",
    "post = posts[0]\n",
    "\n",
    "print(f\"Analyzing: {post.title}\")\n",
    "print(f\"Comments: {len(post.comments)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Analyze with Claude\n",
    "analyzer = ClaudeAnalyzer()\n",
    "result = analyzer.analyze(post)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nüìä FFGA Analysis for: {result.post_title}\\n\")\n",
    "\n",
    "for category in [\"fears\", \"frustrations\", \"goals\", \"aspirations\"]:\n",
    "    ffga = getattr(result, category)\n",
    "    print(f\"**{category.upper()}** [{ffga.sentiment.value}]\")\n",
    "    print(f\"  Summary: {ffga.summary}\")\n",
    "    print(f\"  Quotes: {ffga.quotes[:2]}\")  # First 2 quotes\n",
    "    print()\n",
    "\n",
    "print(f\"üéØ Overall Sentiment: {result.overall_sentiment.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "from kopi_sentiment.analyzer.openai import OpenAIAnalyzer\n",
    "\n",
    "# Fetch a post with comments\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=1)\n",
    "post = posts[0]\n",
    "\n",
    "print(f\"Analyzing: {post.title}\")\n",
    "print(f\"Comments: {len(post.comments)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Analyze with Claude\n",
    "analyzer = OpenAIAnalyzer()\n",
    "result = analyzer.analyze(post)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nüìä FFGA Analysis for: {result.post_title}\\n\")\n",
    "\n",
    "for category in [\"fears\", \"frustrations\", \"goals\", \"aspirations\"]:\n",
    "    ffga = getattr(result, category)\n",
    "    print(f\"**{category.upper()}** [{ffga.sentiment.value}]\")\n",
    "    print(f\"  Summary: {ffga.summary}\")\n",
    "    print(f\"  Quotes: {ffga.quotes[:2]}\")  # First 2 quotes\n",
    "    print()\n",
    "\n",
    "print(f\"üéØ Overall Sentiment: {result.overall_sentiment.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "from kopi_sentiment.analyzer.openai import OpenAIAnalyzer\n",
    "\n",
    "# Fetch a post with comments\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=9)\n",
    "post = posts[-1]\n",
    "\n",
    "print(f\"Analyzing: {post.title}\")\n",
    "print(f\"Comments: {len(post.comments)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Analyze\n",
    "analyzer = OpenAIAnalyzer()\n",
    "result = analyzer.analyze(post)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nüìä FFGA Analysis for: {result.post_title}\\n\")\n",
    "\n",
    "for category in [\"fears\", \"frustrations\", \"goals\", \"aspirations\"]:\n",
    "    ffga = getattr(result, category)\n",
    "    print(f\"**{category.upper()}** [{ffga.sentiment.value}]\")\n",
    "    print(f\"  Summary: {ffga.summary}\")\n",
    "    print(f\"  Quotes: {ffga.quotes[:5]}\")  # First 2 quotes\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "from kopi_sentiment.analyzer.claude import ClaudeAnalyzer\n",
    "\n",
    "# Fetch a post with comments\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.fetch_posts_with_content(limit=9)\n",
    "post = posts[-1]\n",
    "\n",
    "print(f\"Analyzing: {post.title}\")\n",
    "print(f\"Comments: {len(post.comments)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Analyze\n",
    "analyzer = ClaudeAnalyzer()\n",
    "result = analyzer.analyze(post)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nüìä FFGA Analysis for: {result.post_title}\\n\")\n",
    "\n",
    "for category in [\"fears\", \"frustrations\", \"goals\", \"aspirations\"]:\n",
    "    ffga = getattr(result, category)\n",
    "    print(f\"**{category.upper()}** [{ffga.sentiment.value}]\")\n",
    "    print(f\"  Summary: {ffga.summary}\")\n",
    "    print(f\"  Quotes: {ffga.quotes[:5]}\")  # First 5 quotes\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "\n",
    "scraper = RedditScraper()\n",
    "\n",
    "# Test search for \"layoffs\"\n",
    "posts = scraper.search_posts_with_content(\"hdb\", limit=5)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Score: {post.score} | Comments: {len(post.comments)}\")\n",
    "    print(f\"Top comment: {post.comments[0].text[:100] if post.comments else 'None'}...\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "\n",
    "scraper = RedditScraper()\n",
    "\n",
    "# Step 1: Test just the search (no content fetching)\n",
    "posts = scraper.search_posts(\"hdb\", limit=5)\n",
    "print(f\"Found {len(posts)} posts\")\n",
    "\n",
    "# Step 2: If posts found, print them\n",
    "for post in posts:\n",
    "    print(f\"- {post.title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://old.reddit.com/r/singapore/search\"\n",
    "params = {\n",
    "    \"q\": \"hdb\",\n",
    "    \"restrict_sr\": \"on\",\n",
    "    \"sort\": \"comments\",\n",
    "    \"t\": \"month\",\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"\n",
    "})\n",
    "\n",
    "response = session.get(url, params=params)\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"URL: {response.url}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "things = soup.find_all(\"div\", class_=\"thing\")\n",
    "print(f\"Found {len(things)} 'thing' divs\")\n",
    "\n",
    "# Check if there's a search-result class instead\n",
    "search_results = soup.find_all(\"div\", class_=\"search-result\")\n",
    "print(f\"Found {len(search_results)} 'search-result' divs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Clementi sees a new record with its first S$1.5M HDB resale\n",
      "Score: 271 | Comments: 25\n",
      "Top comment: 94 and a half years left on the lease, someone earnt alot off their BTO... Remember when we were com...\n",
      "---\n",
      "Title: Over 13,400 HDB flats to reach MOP in 2026; analysts say supply could moderate resale price growth\n",
      "Score: 106 | Comments: 25\n",
      "Top comment: Calling it we‚Äôre going to see the first $2 mil HDB flat in 2026 Edit: additional. The monitoring wil...\n",
      "---\n",
      "Title: Hougang maisonette resale flat with around 66 years left on lease sells for record S$1.45 million\n",
      "Score: 200 | Comments: 24\n",
      "Top comment: At this rate, the monitoring will only stop and action taken when a Woodlands flat sells for 1+ mill...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "\n",
    "scraper = RedditScraper()\n",
    "\n",
    "# Test search for \"hdb\" posts from past month, sorted by comments\n",
    "posts = scraper.search_posts_with_content(\"hdb\", limit=3)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Score: {post.score} | Comments: {len(post.comments)}\")\n",
    "    if post.comments:\n",
    "        print(f\"Top comment: {post.comments[0].text[:100]}...\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kopi_sentiment.scraper.reddit import RedditScraper\n",
    "# from kopi_sentiment.analyzer.claude import ClaudeAnalyzer\n",
    "from kopi_sentiment.analyzer.openai import OpenAIAnalyzer\n",
    "\n",
    "# 1. Search for HDB posts\n",
    "scraper = RedditScraper()\n",
    "posts = scraper.search_posts_with_content(\"hdb\", limit=2)\n",
    "\n",
    "print(f\"Found {len(posts)} posts about HDB\")\n",
    "print(\"---\")\n",
    "\n",
    "# 2. Analyze each post\n",
    "analyzer = OpenAIAnalyzer()\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"\\nüìù Analyzing: {post.title}\\n\")\n",
    "    \n",
    "    result = analyzer.analyze(post)\n",
    "    \n",
    "    for category in [\"fears\", \"frustrations\", \"goals\", \"aspirations\"]:\n",
    "        ffga = getattr(result, category)\n",
    "        print(f\"**{category.upper()}** [{ffga.sentiment.value}]\")\n",
    "        print(f\"  {ffga.summary}\")\n",
    "        if ffga.quotes:\n",
    "            print(f\"  Quote: \\\"{ffga.quotes[0][:80]}...\\\"\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kopi_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
